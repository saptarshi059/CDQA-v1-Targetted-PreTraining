{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f104b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Saptarshi7/covid_qa_cleaned_CS\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d38506",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af31bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "all_contexts = set()\n",
    "for ctx in dataset['train']['context']:\n",
    "    all_contexts.add(ctx)\n",
    "\n",
    "sorted_all_contexts_on_len = sorted(list(all_contexts), key=len, reverse=True)    \n",
    "top_contexts = len(all_contexts)\n",
    "\n",
    "with open(\"covidqa-longest_len_context.txt\", \"w\") as text_file:\n",
    "    for idx, ctx in enumerate(sorted_all_contexts_on_len):\n",
    "        if idx == top_contexts:\n",
    "            break\n",
    "        text_file.write(ctx)\n",
    "        text_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1d760",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Generating the mapping table: (matched_text, CUI, preferred candidate)\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "texts = json.load(open('covidqa-context-cleaned4MM-MM_output.json'))['AllDocuments']\n",
    "\n",
    "Metamap_Tokenizations = []\n",
    "for doc in tqdm(texts):\n",
    "    for ctx_dict in doc['Document']['Utterances']:\n",
    "        mappings = []\n",
    "        ctx_text = ctx_dict['UttText']\n",
    "        ctx_start_idx = int(ctx_dict['UttStartPos'])\n",
    "        for phr in ctx_dict['Phrases']:\n",
    "            if phr['Mappings'] != []:\n",
    "                for phr_dict in phr[\"Mappings\"][0]['MappingCandidates']: #Choosing the first candidate\n",
    "                    start_idx = int(phr_dict['ConceptPIs'][0]['StartPos']) - ctx_start_idx\n",
    "                    end_idx = start_idx + int(phr_dict['ConceptPIs'][0]['Length'])\n",
    "                    mappings.append((ctx_text[start_idx:end_idx], phr_dict['CandidateCUI'], \\\n",
    "                                     phr_dict['CandidatePreferred']))\n",
    "        Metamap_Tokenizations.append((ctx_text, mappings))\n",
    "\n",
    "entities = set()\n",
    "for mappings in Metamap_Tokenizations:\n",
    "    for tup in mappings[1]:\n",
    "        entities.add(tup[2])\n",
    "print(f\"Number of entities discovered: {len(entities)}\")\n",
    "\n",
    "natural_text = [y[0] for x in Metamap_Tokenizations for y in x[1]]\n",
    "cuis = [y[1] for x in Metamap_Tokenizations for y in x[1]]\n",
    "pc = [y[2] for x in Metamap_Tokenizations for y in x[1]]\n",
    "CUI_Preferred_Concept_Lookup_Table = pd.DataFrame(zip(natural_text, cuis, pc), columns=['natural_text','CUI','Preferred_Concept']).drop_duplicates()\n",
    "CUI_Preferred_Concept_Lookup_Table.to_csv('natural_text_CUI_PC.csv', index=False)\n",
    "print('Our_CUI_PC table generated...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.read_csv('natural_text_CUI_PC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('csarron/bert-base-uncased-squad-v1')\n",
    "model_vocab = list(tokenizer.vocab.keys())\n",
    "pretrained_KGE_df = pd.read_csv('embeddings.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e37339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "for row in tqdm(s.itertuples(), total=s.shape[0]):\n",
    "    '''\n",
    "    If the entity is in the model_vocab remove that row since we don't want another embedding for the same\n",
    "    term. If the entities CUI is not in the list of pretrained ones, remove it since we can't learn a \n",
    "    mapping then.\n",
    "    '''\n",
    "    if (row.natural_text in model_vocab) or (row.CUI not in pretrained_KGE_df[0].to_list()):\n",
    "        s.drop(axis=0, index=row.Index, inplace=True)\n",
    "\n",
    "s.to_csv('Filtered_by_BERT_vocab_and_KGE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.read_csv('Filtered_by_BERT_vocab_and_KGE.csv')\n",
    "s.drop(axis=1, inplace=True, columns=['Unnamed: 0'])\n",
    "s.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d7398",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline('en', package=None, processors={'ner':['anatem',\n",
    "                                                            'bc5cdr',\n",
    "                                                            'bc4chemd',\n",
    "                                                            'bionlp13cg',\n",
    "                                                            'jnlpba',\n",
    "                                                            'linnaeus',\n",
    "                                                            'ncbi_disease',\n",
    "                                                            's800',\n",
    "                                                            'i2b2',\n",
    "                                                            'radiology'], 'tokenize':'default'})\n",
    "                      #tokenize_pretokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5414356",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('ECMO extracorporeal membrane oxygenation')\n",
    "print(doc.entities) #if this is empty, it means, the NER didn't recognize anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531eb18",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Don't need to run this now, since I run it on GPU01. It's extremely slow on cpu!\n",
    "from tqdm.notebook import tqdm\n",
    "for row in tqdm(s.itertuples(), total=s.shape[0]):\n",
    "    prepared_for_NER = [[str(row.natural_text)]]\n",
    "    #i.e. we want to keep only those entries that map to at least 1 entity\n",
    "    if nlp(prepared_for_NER).entities == []: \n",
    "        s.drop(axis=0, index=row.Index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.read_csv('Filtered_by_Stanza_NER.csv')\n",
    "s.drop(axis=1, inplace=True, columns=['Unnamed: 0'])\n",
    "s.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "new_ents = []\n",
    "for i in tqdm(range(dataset['train'].num_rows)):\n",
    "    doc = nlp(dataset['train'][i]['question'])\n",
    "    for ent_dict in doc.entities:\n",
    "        new_ents.append(ent_dict.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
